# -*- coding: utf-8 -*-
"""Medical Insuarance Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UxMA2YbVxbol79in2SyDvhexwUfW1Bji

**1. Importing Libraries**
"""

# main libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#sklearn models and other functions
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder
from xgboost import XGBRegressor
# other libraries
import warnings
warnings.filterwarnings('ignore')
import time
from joblib import dump,load

"""**2. Importing and Reading data**"""

!pip install opendatasets

import opendatasets as od
dataset_url = 'https://www.kaggle.com/datasets/mirichoi0218/insurance'
od.download(dataset_url)
#{"username":"your_kaggle_name","key":"created_by_kaggle"}

"""**Dataset Description**

1. age: age of primary beneficiary

2. sex: Gender either a **female** or **male**

3. bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,
objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9

4. children: Number of children covered by health insurance / Number of dependents

5. smoker: Smoking

6. region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.

7. charges: Individual medical costs billed by health insurance

                     **Categorical columns**
                     1. sex
                     2. Smoker
                     3. Region

                    ** Numerical columns**
                    1. Age
                    2. bmi
                    3. charges
                    4. children



"""

# read the csv file using pandas dataframe
data_path ='/content/insurance/insurance.csv'
dataframe = pd.read_csv(data_path)
# read first five rows
dataframe.head()

# shape of the dataframe
dataframe.shape 
#(1338, 7) 
# 1338 ---> Number of rows in a dataframe
# 7    ---> Number of columns in a dataframe

#information about the dataframe
dataframe.info()

# statistical information about each numerical columns
dataframe.describe().T

# data types of each column
dataframe.dtypes

# names of a columns
dataframe.columns

"""#**3. Data Analysis**"""

# checking for null values
dataframe.isnull().sum()

# correlatiom map
correlation = dataframe.corr()
correlation

#heatmap
sns.heatmap(correlation,annot=True)

"""A strong correlation is observed with smoking patients

**3.1 Distribution of numerical features**
"""

numerical_column = list(dataframe.select_dtypes(['int64','float64']).columns)
categorical_column = list(dataframe.select_dtypes('object').columns)

def plot(df,plot_kind,column_list):
  figure = plt.figure(figsize=(8,5))
  sns.set()
  plot_kind = plot_kind.lower()
  plot_function = {'distplot':sns.distplot,
                   'countplot':sns.countplot}
  if plot_kind == 'distplot':
    for index,column in enumerate(column_list):
      row = len(column_list)/2
      axis = figure.add_subplot(row,2,index+1)
      plot_function[plot_kind](df[column],ax = axis).set_title(f'Distplot of {column}')
    plt.tight_layout()
    plt.show()

  elif plot_kind =='countplot':
    for index,column in enumerate(column_list):
      axis = figure.add_subplot(1,3,index+1)
      plot_function[plot_kind](df[column],ax = axis).set_title(f'countplot of {column}')
      plt.xticks(rotation=90)
    plt.tight_layout()
    plt.show()

plot(dataframe,'distplot',numerical_column)

plot(dataframe,'countplot',categorical_column)

numerical_column

dataframe.dtypes

"""**Dsitribution of charges for smokers**"""

smokers = dataframe[dataframe['smoker']=='yes']
non_smokers = dataframe[dataframe['smoker']=='no']
dataframe['smoker'].value_counts()
sns.countplot(dataframe['smoker']).set_title('Distribution for smokers')

"""**Majority of people do not smoke**"""

fig = plt.figure(figsize=(14,5))
axis = fig.add_subplot(1,2,1)
axis2 = fig.add_subplot(1,2,2)
sns.distplot(dataframe[dataframe.smoker=='yes']['charges'],ax=axis,color='r').set_title('Distribution of charges for smokers')
plt.tight_layout()
sns.distplot(dataframe[dataframe.smoker=='no']['charges'],ax=axis2,color='g').set_title('Distribution of charges for non-smokers')
plt.tight_layout()

plt.figure(figsize=(5,5))
sns.violinplot(data=dataframe,x='sex',y='charges',hue='smoker').set_title('charges for smokers based on the gender')
plt.show()

plt.figure(figsize=(5,5))
sns.boxplot(data=dataframe,x='sex',y='charges',hue='smoker').set_title('charges for smokers based on the gender')
plt.show()

"""How age affect the charges"""

#age distribution
sns.distplot(dataframe['age']).set_title('Age Distribution')

sns.countplot(data=dataframe,x='smoker',hue='sex')

"""**Men smoke more than women**"""

#Does smoking affect the cost of treatment at this age?
plt.figure(figsize=(15,8))
sns.boxplot(x='charges',data=dataframe,y='smoker')

# distribution of childrens
sns.countplot(dataframe['children'])

"""**Most people they do not have childre**

#**4. Data Preprocessing**

**4.1 Label encoding**
"""

# label encoding using sklearn LabelEncoder
def encode(df, method = 'label'):
    df = df.copy()
    get_categorical_column = list(df.select_dtypes('object').columns)
    if method == 'label':
        for column in get_categorical_column:
            encoder = LabelEncoder()
            df[column] = encoder.fit_transform(df[column])
    elif method == 'one_hot':
        df = pd.get_dummies(df, columns=get_categorical_column)
    return df

dataframe= encode(dataframe,'label')

"""#**5. Modeling**"""

#seperate features and target column and turn it int a numpy array
features = dataframe.drop('charges',axis=1).values
target = dataframe['charges'].values

# split dataset into train and test part. 
train_data,test_data,train_labels,test_labels = train_test_split(features,target,test_size=0.2,random_state=0)

# linear regression model, base model
l_model = LinearRegression()
l_model.fit(train_data,train_labels)

# prediction on training data and test data
train_prediction = l_model.predict(train_data)
test_prediction = l_model.predict(test_data)

# r2_Score
train_r2Score = r2_score(train_prediction,train_labels)
test_r2Score = r2_score(test_prediction,test_labels)
print('Accuracy for train data: ',train_r2Score)
print('Accuracy for test data: ',test_r2Score)

"""**5.1 Model Selection**"""

models = [LinearRegression(),XGBRegressor(verbose=0,silent=True),RandomForestRegressor(n_estimators=100,criterion='mse',random_state=1,n_jobs=-1)]
model_results=[]
prediction_results = []
def best_model(model_list):
  for model in model_list:
    start_time = time.time()
    model.fit(train_data,train_labels)
    model_prediction = model.predict(test_data)
    model_r2score = r2_score(model_prediction,test_labels)
    formatted_r2score = round(model_r2score*100,2)
    end_time = time.time()
    execution_time = round(end_time-start_time,2)
    prediction_results.append({'model_name':str(model),'model prediction':model_prediction})
    model_results.append({'model_name':str(model),'modelr2score':formatted_r2score,'execution time':execution_time})
  df = pd.DataFrame(model_results)
  return df,prediction_results

df=best_model(models)[0]
prediction = best_model(models)[1]
df

model_names = ['Linear model','XGB Regressor','Random forest']
plt.bar(model_names, df['modelr2score'])
plt.xlabel('Model')
plt.ylabel('R^2 Score')
plt.title('Model Comparison')
#plt.xticks(rotation=90)
plt.show()

results = df
#save the model
results.to_csv('model_results.csv',index=False)

results.to_csv('model_results.csv', index=False)
dump(results,'model_results.joblib')

"""#**6. Hyperparameter Tuning**"""

models = [LinearRegression(),XGBRegressor(),RandomForestRegressor()]

model_parameters = [
    {'fit_intercept':[True,False],'n_jobs': [1, -1],'normalize': [True, False],'positive': [True, False]},
    {'verbose':[0,1],'silent':[True,False]},
    {'n_estimators':[50,100,200],'criterion':['mse','mae'],'random_state':[1,42]}
]
grid_searc_results = []
def model_tuning(models,parameters):
  for index,model in enumerate(models):
    gscv = GridSearchCV(model,parameters[index],n_jobs=-1,cv=5)
    gscv.fit(features,target)
    grid_searc_results.append({
        'model_name':str(model),
        'best score':gscv.best_score_,
        'best parameter':gscv.best_params_
    })
  return pd.DataFrame(grid_searc_results)

gscv_df = model_tuning(models,model_parameters)
gscv_df